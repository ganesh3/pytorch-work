{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy2LAwZwK0Adfubsjl+b1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh3/pytorch-work/blob/master/Attentation_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Based on article at this [link](https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)"
      ],
      "metadata": {
        "id": "MxLOO-gv8xEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general attention mechanism makes use of three main components, namely the queries ,$Q$ , the keys, $K$ , and the values, $V$. "
      ],
      "metadata": {
        "id": "zgE2ckzB89Af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each query vector,$q=s_{t-1}$, is matched against a database of keys to compute a score value. This matching operation is computed as the dot product of the specific query under consideration with each key vector, $k_i$\n",
        "\n",
        "$\\mathrm{e}_{\\mathrm{q}, \\mathrm{k}_{\\mathrm{i}}}=\\mathrm{q} \\cdot \\mathrm{k}_{\\mathrm{i}}$\n",
        "\n",
        "The scores are passed through a softmax operation to generate the weights:\n",
        "\n",
        "$\\alpha_{\\mathrm{q}, \\mathrm{k}_{\\mathrm{i}}}=\\operatorname{softmax}\\left(\\mathrm{e}_{\\mathrm{q}, \\mathrm{k}_{\\mathrm{i}}}\\right)$\n",
        "\n",
        "The generalized attention is then computed by a weighted sum of the value vectors, $v_k$, where each value vector is paired with a corresponding key:\n",
        "\n",
        "$\\operatorname{attention}(\\mathrm{q}, \\mathrm{K}, \\mathrm{V})=\\sum_{\\mathrm{i}} \\alpha_{\\mathrm{q}, \\mathrm{k}_{\\mathrm{i}}} \\mathrm{v}_{\\mathrm{k}_{\\mathrm{i}}}$"
      ],
      "metadata": {
        "id": "9LbSHDdZ9OuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The General Attention Mechanism with NumPy and SciPy"
      ],
      "metadata": {
        "id": "hFbrNp_dBTAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "np.set_printoptions(precision=5)"
      ],
      "metadata": {
        "id": "mTZROXMjB1op"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DPr0MNk6HioT"
      },
      "outputs": [],
      "source": [
        "# encoder representations of four different words\n",
        "word_1 = np.array([1, 0, 0])\n",
        "word_2 = np.array([0, 1, 0])\n",
        "word_3 = np.array([1, 1, 0])\n",
        "word_4 = np.array([0, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generating the weight matrices\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "NvGp1SuuBngz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_Q = np.random.randint(3, size=(3,3))\n",
        "W_K = np.random.randint(3, size=(3,3))\n",
        "W_V = np.random.randint(3, size=(3,3))"
      ],
      "metadata": {
        "id": "6taz5p2oCALo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_Q, W_K, W_V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsL1bre6Fl4H",
        "outputId": "2266fcff-35fb-4793-c455-e2cb43b3edce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[8, 4, 1],\n",
              "        [3, 6, 7],\n",
              "        [2, 0, 3]]), array([[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 0, 2]]), array([[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [2, 2, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generating the queries, keys and values\n",
        "query_1 = word_1 @ W_Q\n",
        "key_1 = word_1 @ W_K\n",
        "value_1 = word_1 @ W_V\n",
        "\n",
        "query_2 = word_2 @ W_Q\n",
        "key_2 = word_2 @ W_K\n",
        "value_2 = word_2 @ W_V\n",
        "\n",
        "query_3 = word_3 @ W_Q\n",
        "key_3 = word_3 @ W_K\n",
        "value_3 = word_3 @ W_V\n",
        "\n",
        "query_4 = word_4 @ W_Q\n",
        "key_4 = word_4 @ W_K\n",
        "value_4 = word_4 @ W_V"
      ],
      "metadata": {
        "id": "SqNITuWiFnFE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering only the first word for the time being, the next step scores its query vector against all the key vectors using a dot product operation. "
      ],
      "metadata": {
        "id": "BYVQwPXiGcX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = np.array([np.dot(query_1, key_1), np.dot(query_1, key_2), np.dot(query_1, key_3), np.dot(query_1, key_4)])"
      ],
      "metadata": {
        "id": "gmdd1je9GVJf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP62juFwGdF5",
        "outputId": "f5d803ef-5872-4524-e74c-012697018d5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score values are subsequently passed through a softmax operation to generate the weights. Before doing so, it is common practice to divide the score values by the square root of the dimensionality of the key vectors (in this case, three) to keep the gradients stable. "
      ],
      "metadata": {
        "id": "63iPWaYVG-UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = softmax(scores / key_1.shape[0] ** 0.5)"
      ],
      "metadata": {
        "id": "RnTUuiCEG3I-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_m2r7ZSHiFt",
        "outputId": "76078cae-1dba-454e-a0b8-7e661a74381e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.16199, 0.16199, 0.16199, 0.51402])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the attention by a weighted sum of the value vectors\n",
        "attention = (weights[0] * value_1) + (weights[1] * value_2) + (weights[2] * value_3) + (weights[3] * value_4)\n",
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxG5GV9HnWn",
        "outputId": "b58d3705-482a-427c-bb64-ad585643dc11"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.67601, 1.67601, 0.64798])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For faster processing, the same calculations can be implemented in matrix form to generate an attention output for all four words in one go:"
      ],
      "metadata": {
        "id": "T66OVA1VLIca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stacking the word embeddings into a single array\n",
        "words = np.array([word_1, word_2, word_3, word_4])"
      ],
      "metadata": {
        "id": "bP75NhhcLEEM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating the queries, keys and values\n",
        "Q = words @ W_Q\n",
        "K = words @ W_K\n",
        "V = words @ W_V"
      ],
      "metadata": {
        "id": "dFBCKzeuLNBd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scoring the query vectors against all key vectors\n",
        "scores = Q @ K.transpose()"
      ],
      "metadata": {
        "id": "UlC8VbyELQax"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the weights by a softmax operation\n",
        "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)"
      ],
      "metadata": {
        "id": "EWfi2JmHLUv1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the attention by a weighted sum of the value vectors\n",
        "attention = weights @ V"
      ],
      "metadata": {
        "id": "iUluQslgLW_k"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#matches for word1\n",
        "attention[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9mVnPyJLY85",
        "outputId": "cf9e7be7-ab8f-457c-8cc2-23a331ae1fad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.67601, 1.67601, 0.64798])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuYREP5KLaCQ",
        "outputId": "2ab9de19-bc61-4370-808a-d587408d7e6c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.67601, 1.67601, 0.64798],\n",
              "       [1.67601, 1.67601, 0.64798],\n",
              "       [1.84696, 1.84696, 0.30608],\n",
              "       [1.67601, 1.67601, 0.64798]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3tFIz9U2LoGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}