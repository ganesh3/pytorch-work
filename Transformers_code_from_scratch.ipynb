{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1FOg49g28I95vDpDdMpwUViLqTatN8J3D",
      "authorship_tag": "ABX9TyNcMW7rTruT0uy2GbocTK0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh3/pytorch-work/blob/master/Transformers_code_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RWOgkD3feJ4v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding"
      ],
      "metadata": {
        "id": "BDvfDd1OecUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is d_model and max_seq_len?\n",
        "\n",
        "d_model is size of the vector for each input word or character whereas max_seq_len (max sequence length) is the total length of the input words or characters."
      ],
      "metadata": {
        "id": "JB_Mldnrsl0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 10\n",
        "d_model = 6"
      ],
      "metadata": {
        "id": "hhDmKHczeXUl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_i = torch.arange(0, d_model, 2).float()\n",
        "odd_i = torch.arange(1, d_model, 2).float()"
      ],
      "metadata": {
        "id": "lMKTDeDGepDG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_i, odd_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46typboMfJ_d",
        "outputId": "0665f56b-68df-433f-f25f-e504d2c6f5ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 2., 4.]), tensor([1., 3., 5.]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator = torch.pow(10000, even_i/d_model)\n",
        "odd_denominator = torch.pow(10000, (odd_i - 1)/d_model)"
      ],
      "metadata": {
        "id": "wjh4KfaOfDSA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator, odd_denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bndqHsv_fgsJ",
        "outputId": "001dcbdc-f3be-4f3a-fc2e-f84cf43db937"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  1.0000,  21.5443, 464.1590]),\n",
              " tensor([  1.0000,  21.5443, 464.1590]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "even_denominator and odd_denominator are the same. Hence, we can use any one of the them and call it a denominator."
      ],
      "metadata": {
        "id": "-TuvNdFEgxvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbpx2Omslza1",
        "outputId": "125c6ba3-7f7b-411b-bed8-cdd3e4b80d72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator = even_denominator"
      ],
      "metadata": {
        "id": "1edWWF_Hfl6g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(max_seq_len, dtype=torch.float).reshape(max_seq_len, 1)"
      ],
      "metadata": {
        "id": "4ryjGnjqf4VL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q32ZHQVhoKl",
        "outputId": "d7d75528-5012-4b80-b5ce-fc20dff447b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [8.],\n",
              "        [9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the value of the position divided by denominator are calculated as below using division and not inverse.\n",
        "0/1, 1/1, 1/21.5443, 1/464.1590, 2/1, 2/21.5443, 2/464.1590"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha23Npgzm4uV",
        "outputId": "9da1bc3a-1e2e-4176-fb9e-424c6a223a10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0,\n",
              " 1.0,\n",
              " 0.04641598938002163,\n",
              " 0.0021544341486430295,\n",
              " 2.0,\n",
              " 0.09283197876004326,\n",
              " 0.004308868297286059)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position.shape, denominator.shape, position/denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bOyXe7DjdL3",
        "outputId": "750f28e0-e1ce-40bb-d123-793f09791e8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 1]),\n",
              " torch.Size([3]),\n",
              " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [1.0000e+00, 4.6416e-02, 2.1544e-03],\n",
              "         [2.0000e+00, 9.2832e-02, 4.3089e-03],\n",
              "         [3.0000e+00, 1.3925e-01, 6.4633e-03],\n",
              "         [4.0000e+00, 1.8566e-01, 8.6177e-03],\n",
              "         [5.0000e+00, 2.3208e-01, 1.0772e-02],\n",
              "         [6.0000e+00, 2.7850e-01, 1.2927e-02],\n",
              "         [7.0000e+00, 3.2491e-01, 1.5081e-02],\n",
              "         [8.0000e+00, 3.7133e-01, 1.7235e-02],\n",
              "         [9.0000e+00, 4.1774e-01, 1.9390e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.div(position, denominator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI3jf_N9kHnK",
        "outputId": "1f11d3a8-18de-4ddd-864f-063da138dc06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [1.0000e+00, 4.6416e-02, 2.1544e-03],\n",
              "        [2.0000e+00, 9.2832e-02, 4.3089e-03],\n",
              "        [3.0000e+00, 1.3925e-01, 6.4633e-03],\n",
              "        [4.0000e+00, 1.8566e-01, 8.6177e-03],\n",
              "        [5.0000e+00, 2.3208e-01, 1.0772e-02],\n",
              "        [6.0000e+00, 2.7850e-01, 1.2927e-02],\n",
              "        [7.0000e+00, 3.2491e-01, 1.5081e-02],\n",
              "        [8.0000e+00, 3.7133e-01, 1.7235e-02],\n",
              "        [9.0000e+00, 4.1774e-01, 1.9390e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_PE = torch.sin(position/denominator)\n",
        "odd_PE = torch.cos(position/denominator)"
      ],
      "metadata": {
        "id": "51e70w2zhpMp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_PE, odd_PE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4IKz5hi-pA",
        "outputId": "47510ee1-4f62-4b5c-f9e6-2ebd15e75efb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "         [ 0.8415,  0.0464,  0.0022],\n",
              "         [ 0.9093,  0.0927,  0.0043],\n",
              "         [ 0.1411,  0.1388,  0.0065],\n",
              "         [-0.7568,  0.1846,  0.0086],\n",
              "         [-0.9589,  0.2300,  0.0108],\n",
              "         [-0.2794,  0.2749,  0.0129],\n",
              "         [ 0.6570,  0.3192,  0.0151],\n",
              "         [ 0.9894,  0.3629,  0.0172],\n",
              "         [ 0.4121,  0.4057,  0.0194]]),\n",
              " tensor([[ 1.0000,  1.0000,  1.0000],\n",
              "         [ 0.5403,  0.9989,  1.0000],\n",
              "         [-0.4161,  0.9957,  1.0000],\n",
              "         [-0.9900,  0.9903,  1.0000],\n",
              "         [-0.6536,  0.9828,  1.0000],\n",
              "         [ 0.2837,  0.9732,  0.9999],\n",
              "         [ 0.9602,  0.9615,  0.9999],\n",
              "         [ 0.7539,  0.9477,  0.9999],\n",
              "         [-0.1455,  0.9318,  0.9999],\n",
              "         [-0.9111,  0.9140,  0.9998]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_PE.shape, odd_PE.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ocxcuYjAR9",
        "outputId": "9e054a45-6812-4d6f-a139-7e08914b6f10"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 3]), torch.Size([10, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked = torch.stack([even_PE, odd_PE], dim=2)"
      ],
      "metadata": {
        "id": "TvwTEZnVjHrt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3rDhfZlnxWe",
        "outputId": "09d5411f-de0c-44a0-cbf3-6ff888a6f8eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1xXsTuFn5ZL",
        "outputId": "93cd93f1-38ac-4abc-aa39-0110e27d6626"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000]],\n",
              "\n",
              "        [[ 0.8415,  0.5403],\n",
              "         [ 0.0464,  0.9989],\n",
              "         [ 0.0022,  1.0000]],\n",
              "\n",
              "        [[ 0.9093, -0.4161],\n",
              "         [ 0.0927,  0.9957],\n",
              "         [ 0.0043,  1.0000]],\n",
              "\n",
              "        [[ 0.1411, -0.9900],\n",
              "         [ 0.1388,  0.9903],\n",
              "         [ 0.0065,  1.0000]],\n",
              "\n",
              "        [[-0.7568, -0.6536],\n",
              "         [ 0.1846,  0.9828],\n",
              "         [ 0.0086,  1.0000]],\n",
              "\n",
              "        [[-0.9589,  0.2837],\n",
              "         [ 0.2300,  0.9732],\n",
              "         [ 0.0108,  0.9999]],\n",
              "\n",
              "        [[-0.2794,  0.9602],\n",
              "         [ 0.2749,  0.9615],\n",
              "         [ 0.0129,  0.9999]],\n",
              "\n",
              "        [[ 0.6570,  0.7539],\n",
              "         [ 0.3192,  0.9477],\n",
              "         [ 0.0151,  0.9999]],\n",
              "\n",
              "        [[ 0.9894, -0.1455],\n",
              "         [ 0.3629,  0.9318],\n",
              "         [ 0.0172,  0.9999]],\n",
              "\n",
              "        [[ 0.4121, -0.9111],\n",
              "         [ 0.4057,  0.9140],\n",
              "         [ 0.0194,  0.9998]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "PE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhwa5xCWoChg",
        "outputId": "a48dd4ab-bedb-4485-b9b8-c5d95bf0a0b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
              "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
              "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
              "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
              "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
              "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
              "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PE.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ib8uFfoZBI",
        "outputId": "2f939356-1cfc-462e-ea17-5ead9226ed00"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Creation for positional encoding"
      ],
      "metadata": {
        "id": "7S7dRNVionRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, max_seq_len, d_model):\n",
        "    super().__init__()\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self):\n",
        "    even_i = torch.arange(0, self.d_model, 2).float()\n",
        "    denominator = torch.pow(10000, even_i/d_model)\n",
        "    position = torch.arange(self.max_seq_len, dtype=torch.float).reshape(self.max_seq_len, 1)\n",
        "    even_PE = torch.sin(position/denominator)\n",
        "    odd_PE = torch.cos(position/denominator)\n",
        "    stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "    PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "    return PE"
      ],
      "metadata": {
        "id": "M3Nbe1LCofrl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PositionalEncoding(d_model=6, max_seq_len=10)\n",
        "pe.forward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6oCgiJQo2TK",
        "outputId": "88c6c42c-a76a-4371-c0da-2bee129a78c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
              "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
              "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
              "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
              "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
              "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
              "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPQ-4sOHrmAk",
        "outputId": "21fb2533-778f-44a2-c00e-be46495d8f94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PositionalEncoding()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Attention"
      ],
      "metadata": {
        "id": "KJQdTi0AN0OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "knXCHHqvrpnB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Data for query, key, and value vectors\n",
        "L, d_k, d_v = 4, 8, 8\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)"
      ],
      "metadata": {
        "id": "7YxUxWgBO28K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q, q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfF--TbhPsUs",
        "outputId": "9b35056d-f5d0-4e13-b53c-f3cf9fda84a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.18185525,  1.20285346,  0.84895926, -1.85361658,  0.3067406 ,\n",
              "         -1.15625659, -0.32583117,  1.98205115],\n",
              "        [-0.11040212, -0.12054249,  0.16393633,  0.31795924, -0.1098013 ,\n",
              "         -0.16196023,  0.515932  ,  1.73909573],\n",
              "        [ 0.57051295, -1.55103972,  1.26124308, -0.52197073,  0.07943291,\n",
              "          0.81313755, -0.93452796, -0.01305509],\n",
              "        [-1.36582104, -2.36551209, -2.01065348, -0.57098784, -0.59060721,\n",
              "         -1.3934979 , -0.61325846,  0.51319789]]),\n",
              " (4, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k, k.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAiIAXj8Rvvg",
        "outputId": "924ddc55-bd71-4da8-c527-7e7ce4707ae7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.23496844,  0.24754314,  0.16154535,  0.64276261, -1.04349571,\n",
              "          0.51490801,  0.44673368, -0.44048445],\n",
              "        [ 0.61871625, -1.49159477,  0.87705042,  0.58481099,  2.87007328,\n",
              "          1.11323109, -0.63494364, -0.11069473],\n",
              "        [ 0.44062828, -1.01982783, -0.29843286, -1.14346986,  0.38451584,\n",
              "          0.45089043, -2.41305085,  0.54940015],\n",
              "        [ 0.44769648,  0.0138322 ,  0.53586962, -0.74420718,  1.72422598,\n",
              "          0.14949841, -0.91771104, -1.60779412]]),\n",
              " (4, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v, v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIKIoqRtRxGm",
        "outputId": "2c7b83cb-381c-4269-d38a-7327cd9e52bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.20545246, -0.1180561 , -1.52660273,  0.02147769, -0.16144093,\n",
              "          0.20391106,  0.52396854,  0.9272886 ],\n",
              "        [-0.43832067, -1.08375072,  0.51076884,  0.05280151, -0.10517605,\n",
              "          0.34501719, -1.76393002, -0.22765087],\n",
              "        [-1.0278198 ,  1.38001859, -1.34983878,  0.63331007, -0.08606777,\n",
              "          0.77282203, -1.54744266,  1.51447704],\n",
              "        [-0.36648509,  0.23237707, -1.03977619, -0.24762045,  0.39092937,\n",
              "          0.9479824 , -0.67053554,  0.72928491]]),\n",
              " (4, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\text { self attention }=\\operatorname{softmax}\\left(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}+M\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "\\text { new } \\mathrm{V}= self attention. V\n",
        "$$"
      ],
      "metadata": {
        "id": "6XOCXhVtPQM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kr3f89tR3BH",
        "outputId": "47419d44-c636-4b63-f09c-e6fbab6dcfb1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.73333288, -2.66545297,  2.03115133, -0.76205133],\n",
              "       [-0.32930288, -0.57431396, -0.74297185, -3.68299247],\n",
              "       [-0.45758343,  5.19543392,  4.69870921,  2.43541814],\n",
              "       [-2.19955854, -2.32782954,  3.96991028, -2.78569689]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why we need sqrt(d_k) in denominator?\n",
        "\n",
        "q.var(), k.var(), np.matmul(q, k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC71EA3qSBuV",
        "outputId": "c67223ea-c2ee-420f-a768-9d77e950a8e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0777683180599649, 1.013878680220582, 7.6731776585516105)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = np.matmul(q, k.T)/math.sqrt(d_k)"
      ],
      "metadata": {
        "id": "O-mpZggeSW4e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the reduction in variance of the 'scaled' or the 'np.matmul product' vector i.e. 5.4557 vs 0.6819\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqItov8RSls5",
        "outputId": "2ee94b4c-1d13-49cd-cff9-f689b5f1ae9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0777683180599649, 1.013878680220582, 0.959147207318951)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCV77bPBSqKw",
        "outputId": "11576a9b-3121-49ad-abc6-67c3ae1e8e97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.96637911, -0.94237994,  0.71812044, -0.26942583],\n",
              "       [-0.11642615, -0.20305065, -0.26268022, -1.30213448],\n",
              "       [-0.16178017,  1.83686328,  1.66124457,  0.86105034],\n",
              "       [-0.77766138, -0.82301203,  1.40357524, -0.98489258]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masking\n",
        "\n",
        "\n",
        "1. This is to ensure words don't get context from words generated in the future.\n",
        "2. Not required in the encoders, but required in the decoders\n"
      ],
      "metadata": {
        "id": "1yjuXbHPTAZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.tril(np.ones((L, L)))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECVdgENSS9ws",
        "outputId": "3a68a58a-61c3-4863-ca99-dd939d0e0bd4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = - np.infty\n",
        "mask[mask == 1] = 0"
      ],
      "metadata": {
        "id": "EkTCvLjFdnho"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5VrVfj3d9pL",
        "outputId": "7757d31a-c6a4-4a69-86ee-c6d6c36b1bef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled + mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FQvOdy8d-SY",
        "outputId": "d48b13fa-00fa-46d4-916d-b463914cc52f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.96637911,        -inf,        -inf,        -inf],\n",
              "       [-0.11642615, -0.20305065,        -inf,        -inf],\n",
              "       [-0.16178017,  1.83686328,  1.66124457,        -inf],\n",
              "       [-0.77766138, -0.82301203,  1.40357524, -0.98489258]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Softmax\n",
        "\n",
        "$\\operatorname{softmax}=\\frac{e^{x_i}}{\\sum_j e_j^x}$"
      ],
      "metadata": {
        "id": "pPb1bfe-eIH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
      ],
      "metadata": {
        "id": "4juB3qTUeBdP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = softmax(scaled + mask)"
      ],
      "metadata": {
        "id": "mss25dn1emvz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax is applied so that the infinity values become zero and essentially acts as an unknown for the model to predict i.e. the next word or character\n",
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMSvfNu-erPe",
        "outputId": "93601552-de6e-4944-e97b-cc9c23a554a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.52164259, 0.47835741, 0.        , 0.        ],\n",
              "       [0.06863609, 0.50646841, 0.4248955 , 0.        ],\n",
              "       [0.08601598, 0.08220223, 0.76186527, 0.06991652]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v = np.matmul(attention, v)"
      ],
      "metadata": {
        "id": "bTqB4MzgeyLZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBR-fIbWfFPK",
        "outputId": "4f126dfa-0e0a-4ca5-d366-68fceaf8a70d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.20545246, -0.1180561 , -1.52660273,  0.02147769, -0.16144093,\n",
              "         0.20391106,  0.52396854,  0.9272886 ],\n",
              "       [ 0.41914141, -0.58000327, -0.55201095,  0.03646167, -0.13452621,\n",
              "         0.27141023, -0.57046468,  0.37481475],\n",
              "       [-0.57597403,  0.02937527, -0.41963218,  0.29730704, -0.10091883,\n",
              "         0.51710457, -1.5149131 ,  0.59184196],\n",
              "       [-0.74102633,  0.96839379, -1.19041871,  0.47137202, -0.06077183,\n",
              "         0.70096668, -1.32575365,  1.26586475]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8YVn_P_fIx-",
        "outputId": "25374dd0-1c87-4dfc-a09e-2389fd0573cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.20545246, -0.1180561 , -1.52660273,  0.02147769, -0.16144093,\n",
              "         0.20391106,  0.52396854,  0.9272886 ],\n",
              "       [-0.43832067, -1.08375072,  0.51076884,  0.05280151, -0.10517605,\n",
              "         0.34501719, -1.76393002, -0.22765087],\n",
              "       [-1.0278198 ,  1.38001859, -1.34983878,  0.63331007, -0.08606777,\n",
              "         0.77282203, -1.54744266,  1.51447704],\n",
              "       [-0.36648509,  0.23237707, -1.03977619, -0.24762045,  0.39092937,\n",
              "         0.9479824 , -0.67053554,  0.72928491]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  d_k = q.shape[-1]\n",
        "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled + mask\n",
        "\n",
        "  attention = softmax(scaled)\n",
        "  out = np.matmul(attention, v)\n",
        "\n",
        "  return out, attention"
      ],
      "metadata": {
        "id": "Y6vz8a39fOj5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)"
      ],
      "metadata": {
        "id": "lbIfvwujo4Er"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v, values, attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-Y7FXqo8m4",
        "outputId": "ac744193-c974-4c99-f97a-ddae7eee87a3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.20545246, -0.1180561 , -1.52660273,  0.02147769, -0.16144093,\n",
              "          0.20391106,  0.52396854,  0.9272886 ],\n",
              "        [-0.43832067, -1.08375072,  0.51076884,  0.05280151, -0.10517605,\n",
              "          0.34501719, -1.76393002, -0.22765087],\n",
              "        [-1.0278198 ,  1.38001859, -1.34983878,  0.63331007, -0.08606777,\n",
              "          0.77282203, -1.54744266,  1.51447704],\n",
              "        [-0.36648509,  0.23237707, -1.03977619, -0.24762045,  0.39092937,\n",
              "          0.9479824 , -0.67053554,  0.72928491]]),\n",
              " array([[ 1.20545246, -0.1180561 , -1.52660273,  0.02147769, -0.16144093,\n",
              "          0.20391106,  0.52396854,  0.9272886 ],\n",
              "        [ 0.41914141, -0.58000327, -0.55201095,  0.03646167, -0.13452621,\n",
              "          0.27141023, -0.57046468,  0.37481475],\n",
              "        [-0.57597403,  0.02937527, -0.41963218,  0.29730704, -0.10091883,\n",
              "          0.51710457, -1.5149131 ,  0.59184196],\n",
              "        [-0.74102633,  0.96839379, -1.19041871,  0.47137202, -0.06077183,\n",
              "          0.70096668, -1.32575365,  1.26586475]]),\n",
              " array([[1.        , 0.        , 0.        , 0.        ],\n",
              "        [0.52164259, 0.47835741, 0.        , 0.        ],\n",
              "        [0.06863609, 0.50646841, 0.4248955 , 0.        ],\n",
              "        [0.08601598, 0.08220223, 0.76186527, 0.06991652]]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi head Attention"
      ],
      "metadata": {
        "id": "RSZ8e_gfpSPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Tr4gDCCGpAps"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence length is the length of input sequence\n",
        "sequence_length = 4\n",
        "#batch size is the size of the batch passed to the dataloader for processing\n",
        "batch_size = 1\n",
        "# output of the attention unit for every word\n",
        "d_model = 512\n",
        "#input dimension is the size of the input dimension for each word or character\n",
        "# i.e. If the sentence is 'I live in India' then the dimension to represent each word like 'I', 'live', 'in', 'India' is of size 512\n",
        "input_dim = 512"
      ],
      "metadata": {
        "id": "lLw7MxFQlQHN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the x value below is the value post the positional encoding step and is an input to the multi head attention step of the encoder\n",
        "x = torch.randn(batch_size, sequence_length, d_model)"
      ],
      "metadata": {
        "id": "YuX0vIJem9Y4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOMXDBTLnD67",
        "outputId": "47a1a65f-c21f-45b3-9e5b-0f25c0be0a7b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiplied by 3 in order to have q, k, v vectors using d_model\n",
        "qkv_layer = nn.Linear(input_dim, 3 * d_model)"
      ],
      "metadata": {
        "id": "6wAs08UInGXy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qkv_layer(x)"
      ],
      "metadata": {
        "id": "NVQZH77LnVMz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05HSSYcQnZfW",
        "outputId": "1eecfcf1-85cd-421b-a65f-922fdb7fe67a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EdQRjfuUncn4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yval = torch.histc(qkv, bins=200, min=-3, max=3)\n",
        "xval = np.arange(-1, 1, 0.01) *3"
      ],
      "metadata": {
        "id": "LjhQntJpz_c6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(xval, yval, align='center', color=['green'])\n",
        "plt.title('QKV Distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "_EVVbGBU0cLM",
        "outputId": "92c5b168-9ff7-4a01-8e13-a4c2ffe24533"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'QKV Distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 8\n",
        "head_dim = d_model // num_heads\n",
        "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
      ],
      "metadata": {
        "id": "aOl_gpsT0wvn"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zaky7WXt7a-Z",
        "outputId": "0b460644-10b5-402b-dc8c-7a2489b51377"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [batch_size, num_heads, sequence_length, 3*head_dim]\n",
        "qkv = qkv.permute(0, 2, 1, 3)"
      ],
      "metadata": {
        "id": "laV0EozP7csr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRXnTxA_7u8P",
        "outputId": "035142e6-046e-452d-e877-b3a113726c7e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q, k, v = qkv.chunk(3, dim = -1)\n",
        "q.shape, k.shape, v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjglqmBv7wME",
        "outputId": "f6a5b050-a3be-42de-d581-20bb0b273902"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Self attention for multiple heads\n",
        "\n",
        "$$\n",
        "\\text { self attention }=\\operatorname{softmax}\\left(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}+M\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "\\text { new } \\mathrm{V}= self attention. V\n",
        "$$"
      ],
      "metadata": {
        "id": "eHL6KUqm9xFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_k - q.shape[-1]\n",
        "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XeFwVz39qia",
        "outputId": "258d86ac-1266-4bda-9740-ec312a1e39a5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kUJFpi8-38u",
        "outputId": "0751b08d-72e2-4997-a175-e646ea10506f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-879c2705464e>:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  k.T.shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randn(2, 3)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJUK4ToF-72F",
        "outputId": "549ea8d4-2379-4b2a-b9b4-41093155df7e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO12TCAeMNQh",
        "outputId": "47ba45cc-9b83-4470-ab39-8528ea01c628"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6678, -0.1673, -0.9192],\n",
              "        [-0.5707,  0.3481, -0.1764]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT2Dgn5xMDHr",
        "outputId": "d9d048ca-7486-428b-f020-0b656ca36fd5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6678, -0.5707],\n",
              "        [-0.1673,  0.3481],\n",
              "        [-0.9192, -0.1764]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.transpose(1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwMWytspMLTE",
        "outputId": "02da64a7-5e25-453b-8d3c-4164a4e7a683"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6678, -0.5707],\n",
              "        [-0.1673,  0.3481],\n",
              "        [-0.9192, -0.1764]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.transpose(-1, -2) == k.transpose(-2, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S789xT9zMQQw",
        "outputId": "86533f02-121b-4b1e-c15b-e53810a889d3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]],\n",
              "\n",
              "         [[True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          ...,\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True],\n",
              "          [True, True, True, True]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.transpose(-1, -2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7TrCkJYMeIs",
        "outputId": "7de5a1a7-bbd3-40a3-e90d-1adc2765d69b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 64, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.full(scaled.size(), float('-inf'))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36UQMUJOMjxp",
        "outputId": "2a449e49-943f-4070-be49-ec6c5f89e926"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]],\n",
              "\n",
              "         [[-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(mask, diagonal=1)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iKsUvV9QF7D",
        "outputId": "3ec1e61b-c984-48d0-ca33-ca437c26a187"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]],\n",
              "\n",
              "         [[0., -inf, -inf, -inf],\n",
              "          [0., 0., -inf, -inf],\n",
              "          [0., 0., 0., -inf],\n",
              "          [0., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0][1], mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRo-zwlnQVe3",
        "outputId": "53a7c2dc-4ba3-4141-bbb6-7e6af0e9c982"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., -inf, -inf, -inf],\n",
              "         [0., 0., -inf, -inf],\n",
              "         [0., 0., 0., -inf],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.Size([1, 8, 4, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(scaled+mask)[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOxCmW6PQZNm",
        "outputId": "4359d9b7-8b36-4c1a-8ae7-81957e0c1949"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9914,    -inf,    -inf,    -inf],\n",
              "        [ 1.1568,  1.7453,    -inf,    -inf],\n",
              "        [-0.5933, -0.1951, -0.6222,    -inf],\n",
              "        [ 0.7502, -1.8816,  1.5439,  1.2009]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled += mask"
      ],
      "metadata": {
        "id": "7BMmB6N-Qmtr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = F.softmax(scaled, dim=-1)"
      ],
      "metadata": {
        "id": "BHL-CmQrQpjV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUcW9uTZQ0CP",
        "outputId": "612d7891-24d6-4c21-fdc3-d387702a24e1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxWwV0hiQ3pi",
        "outputId": "0e7f01de-607b-4dfd-ccd1-af91e24cff81"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3570, 0.6430, 0.0000, 0.0000],\n",
              "        [0.2890, 0.4303, 0.2807, 0.0000],\n",
              "        [0.2061, 0.0148, 0.4557, 0.3234]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = torch.matmul(attention, v)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYVsBRccQ5aP",
        "outputId": "f4dea454-ac55-46d7-eeea-28c1b414e4e7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function"
      ],
      "metadata": {
        "id": "jQw1gTyGUUto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "  d_k = q.size()[-1]\n",
        "  scaled = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled += mask\n",
        "  attention = F.softmax(scaled, dim=-1)\n",
        "  values = torch.matmul(attention, v)\n",
        "  return values, attention"
      ],
      "metadata": {
        "id": "vdL2wvl9REWJ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product(q, k, v, mask=mask)"
      ],
      "metadata": {
        "id": "LlwpW0SgU6Nr"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWxOjFUcVBbC",
        "outputId": "f3b3af4f-9ebc-416b-ae6e-aaeb27218f89"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucwFJTlGVCnW",
        "outputId": "cbc97e39-4cc8-4a59-d225-8b7508e21074"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4482, 0.5518, 0.0000, 0.0000],\n",
              "        [0.3184, 0.3665, 0.3151, 0.0000],\n",
              "        [0.2570, 0.1014, 0.3403, 0.3014]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.size() #for every batch, head, sequence of word, the value vector of size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XQKH1HeVFJR",
        "outputId": "2f02a0ed-df26-4889-9d0c-f342bf47fb43"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all the heads together to match the input dimension\n",
        "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo80e03mVTyn",
        "outputId": "51265659-63a4-45bb-ec33-b5f7fc4d4042"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# heads can learn from each other and hence a feedforward linear layer\n",
        "linear_layer = nn.Linear(d_model, d_model)"
      ],
      "metadata": {
        "id": "HT-T0EvjVi6q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = linear_layer(values)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ouePBiVlkQ",
        "outputId": "dca6f90a-f6ca-488f-cf2f-b4db606cfb14"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# much more context aware than the input\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ6TmWU0VqUV",
        "outputId": "0bde1214-a775-4722-9238-3bae2712bac0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2441, -0.2797,  0.3715,  ..., -0.1083, -0.5153,  0.1653],\n",
              "         [ 0.0529, -0.2232, -0.0598,  ..., -0.3440,  0.1075, -0.1082],\n",
              "         [-0.2864,  0.2092, -0.3389,  ..., -0.4216, -0.2365, -0.3041],\n",
              "         [-0.0094, -0.2157,  0.4775,  ...,  0.0918,  0.3671,  0.1379]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Class"
      ],
      "metadata": {
        "id": "hb48NLfKljmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "  d_k = q.size()[-1]\n",
        "  scaled = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled += mask\n",
        "  attention = F.softmax(scaled, dim=-1)\n",
        "  values = torch.matmul(attention, v)\n",
        "  return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self, input_dim, d_model, num_heads):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_model // num_heads\n",
        "    self.qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
        "    self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    batch_size, sequence_length, input_dim = x.size() # 30 x 200 x 512\n",
        "    print(f\"x.size(): {x.size()}\")\n",
        "    qkv = self.qkv_layer(x) # 30 x 200 x 1536\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim) # 30 x 200 x 8 x 192\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    qkv = qkv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 192\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    q, k, v = torch.chunk(qkv, 3, dim=-1) # q: 30 x 8 x 200 x 64, k: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "    print(f\"q.size(): {q.size()} , k.size(): {k.size()}, v.size(): {v.size()}\")\n",
        "    values, attention = scaled_dot_product(q, k, v, mask) # values: 30 x 8 x 200 x 64\n",
        "    print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "    values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)# 30 x 200 x 512\n",
        "    print(f\"values.size(): {values.size()}\")\n",
        "    out = self.linear_layer(values) # 30 x 200 x 512\n",
        "    print(f\"out.size(): {out.size()}\")\n",
        "    return out # 30 x 200 x 512"
      ],
      "metadata": {
        "id": "bgGvP1QLVtOF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input"
      ],
      "metadata": {
        "id": "dHuWRsm9oued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1024\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "\n",
        "batch_size = 30\n",
        "sequence_length = 5"
      ],
      "metadata": {
        "id": "wG46r8reoqYb"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((batch_size, sequence_length, input_dim))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAmJYeMJozYC",
        "outputId": "0ff43e02-0e61-48b1-ff03-d9de1ddfd85f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 5, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
        "out = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyS56FM_o6ju",
        "outputId": "7d797007-bf43-4806-a288-84a6f61b78b7"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.size(): torch.Size([30, 5, 1024])\n",
            "qkv.size(): torch.Size([30, 5, 1536])\n",
            "qkv.size(): torch.Size([30, 5, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 5, 192])\n",
            "q.size(): torch.Size([30, 8, 5, 64]) , k.size(): torch.Size([30, 8, 5, 64]), v.size(): torch.Size([30, 8, 5, 64])\n",
            "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
            "values.size(): torch.Size([30, 5, 512])\n",
            "out.size(): torch.Size([30, 5, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization with Residual Connection"
      ],
      "metadata": {
        "id": "KXEbNIJcvTvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])"
      ],
      "metadata": {
        "id": "vJq4uydPpRJz"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_o7_oTGvnRG",
        "outputId": "575264c2-d0fb-4d24-e4de-9a0d36c3504b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B, S, E = inputs.size()"
      ],
      "metadata": {
        "id": "CAOLFXxqvoeY"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.reshape(S, B, E)\n",
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae0Dv5xZvwOC",
        "outputId": "c481e375-93cb-4eb4-fdf7-da1a2240e415"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_shape = inputs.size()[-2:]"
      ],
      "metadata": {
        "id": "06uaUzC4v3RE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4by6kX4Av-tu",
        "outputId": "32e77026-fed1-4c7b-8b3d-26fe00e0d4b0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "beta = nn.Parameter(torch.zeros(parameter_shape))"
      ],
      "metadata": {
        "id": "cFMivoQMwBNL"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma.shape, gamma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQsvAULMwmcO",
        "outputId": "d5010d4c-d2ce-4fcd-c9a5-287b3d0074bd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]),\n",
              " Parameter containing:\n",
              " tensor([[1., 1., 1.]], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beta.shape, beta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XktyO_iwosu",
        "outputId": "a949fcd0-b696-49f8-ae80-a2fb757a573c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]),\n",
              " Parameter containing:\n",
              " tensor([[0., 0., 0.]], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [-(i+1) for i in range(len(parameter_shape))]"
      ],
      "metadata": {
        "id": "hAVE8QARwsPE"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range(len(parameter_shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDrx3zEr1L90",
        "outputId": "7b5f189d-f8b3-48fe-e6f7-58cb331513d0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92kKyS2K1E-T",
        "outputId": "4c395349-5864-4d90-da99-e8e5d1f4f761"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, -2]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = inputs.mean(dim=dims, keepdim=True)\n",
        "mean.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQRnqH-51JQS",
        "outputId": "85a2e8fd-9fb1-43ef-bf0c-252ab7e9f0f0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5buTO8-19C6",
        "outputId": "07574a7f-9e9b-4f5f-a368-3e2a7724ca14"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2000]],\n",
              "\n",
              "        [[0.2333]]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "epsilon = 1e-5\n",
        "std = (var + epsilon).sqrt()\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQL0Has31iMm",
        "outputId": "cb6e61f5-4df7-411e-a14f-f466fe6429a6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0817]],\n",
              "\n",
              "        [[0.1886]]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (inputs - mean) / std\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9040YvU14BI",
        "outputId": "b36f2d39-f5cf-450b-fc90-c9e7b53f512f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = gamma * y + beta\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF8ovZek2E4z",
        "outputId": "347ca6c9-c21c-44d1-d112-b05dbdb89aca"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Class"
      ],
      "metadata": {
        "id": "EY9LppRH2SJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization():\n",
        "  def __init__(self, parameter_shape, eps=1e-5):\n",
        "    self.paramater_shape = parameter_shape\n",
        "    self.eps = eps\n",
        "    self.gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "    self.beta = nn.Parameter(torch.zeros(parameter_shape))\n",
        "\n",
        "  def forward(self, x):\n",
        "    dims = [-(i+1) for i in range(len(self.paramater_shape))]\n",
        "    mean = x.mean(dim=dims, keepdim=True)\n",
        "    print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "    var = ((x - mean)**2).mean(dim=dims, keepdim=True)\n",
        "    std = (var + self.eps).sqrt()\n",
        "    print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "    y = (x - mean) / std\n",
        "    print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
        "    out = self.gamma * y + self.beta\n",
        "    return out"
      ],
      "metadata": {
        "id": "xXAh6JVA2PSn"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8"
      ],
      "metadata": {
        "id": "QcA457cfqSdQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)"
      ],
      "metadata": {
        "id": "FbURHU9Krr6J"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWyfZUWrwkl",
        "outputId": "e571e9ee-4e09-4d64-e07d-894d14beff86"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.size()[-1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMBuLgLryJJ",
        "outputId": "9acb8db6-dd59-4058-ece7-a563cd243735"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_norm = LayerNormalization(inputs.size()[-1:])"
      ],
      "metadata": {
        "id": "fiSla9tvr6ky"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = layer_norm.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY9sJ_-UsEGy",
        "outputId": "db2e42d3-b96b-435f-dd9d-77970726c61a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[ 0.1427],\n",
            "         [ 0.1714],\n",
            "         [ 0.4639]],\n",
            "\n",
            "        [[ 0.2785],\n",
            "         [ 0.1854],\n",
            "         [-0.0836]],\n",
            "\n",
            "        [[ 0.3625],\n",
            "         [ 0.3706],\n",
            "         [ 0.0044]],\n",
            "\n",
            "        [[-0.4096],\n",
            "         [ 0.4235],\n",
            "         [ 0.5415]],\n",
            "\n",
            "        [[ 0.1653],\n",
            "         [-0.1481],\n",
            "         [-0.0091]]])\n",
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[ 0.1427],\n",
            "         [ 0.1714],\n",
            "         [ 0.4639]],\n",
            "\n",
            "        [[ 0.2785],\n",
            "         [ 0.1854],\n",
            "         [-0.0836]],\n",
            "\n",
            "        [[ 0.3625],\n",
            "         [ 0.3706],\n",
            "         [ 0.0044]],\n",
            "\n",
            "        [[-0.4096],\n",
            "         [ 0.4235],\n",
            "         [ 0.5415]],\n",
            "\n",
            "        [[ 0.1653],\n",
            "         [-0.1481],\n",
            "         [-0.0091]]])\n",
            "y \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.1609,  0.1297, -0.8857, -0.9327,  1.5279, -0.4637,  1.7052,\n",
            "          -0.9196],\n",
            "         [ 0.9129, -1.0526, -1.0106, -0.0090,  0.3860,  1.2846, -1.5021,\n",
            "           0.9908],\n",
            "         [-0.2124,  1.3674,  0.2757,  0.2612, -1.0787,  0.9681,  0.3473,\n",
            "          -1.9285]],\n",
            "\n",
            "        [[-0.6856, -0.2756,  1.6648,  0.1313,  0.3549,  1.2445, -1.1006,\n",
            "          -1.3338],\n",
            "         [-0.7793, -0.4038, -1.2413,  1.0402,  1.0650,  1.4606, -1.1570,\n",
            "           0.0155],\n",
            "         [-0.8253,  2.5020, -0.2204, -0.4250, -0.0806, -0.7028, -0.5102,\n",
            "           0.2624]],\n",
            "\n",
            "        [[ 0.3938, -1.0211,  1.6536, -0.1486, -1.1000,  1.0743, -1.2380,\n",
            "           0.3860],\n",
            "         [-1.8895,  0.4337,  0.1537,  1.5198, -0.4807,  1.0279, -0.7873,\n",
            "           0.0224],\n",
            "         [ 0.1941, -1.0414,  1.1188,  0.1779,  1.5497, -1.5884,  0.3356,\n",
            "          -0.7463]],\n",
            "\n",
            "        [[ 0.5531,  0.1819,  0.1126,  1.0831,  1.2361, -0.7247, -2.0696,\n",
            "          -0.3724],\n",
            "         [-0.1287,  1.4346, -1.0927,  0.8816, -0.0355,  0.9872, -1.6881,\n",
            "          -0.3585],\n",
            "         [ 1.3358, -0.1853, -0.4068, -1.0004, -0.8232,  1.5553,  0.7123,\n",
            "          -1.1877]],\n",
            "\n",
            "        [[-0.9236,  1.2348, -0.0750, -0.0378,  0.5757,  0.2988, -2.0561,\n",
            "           0.9833],\n",
            "         [ 1.2886,  0.7022, -0.7959,  0.0343, -2.0676,  0.7791, -0.3753,\n",
            "           0.4346],\n",
            "         [ 0.6213, -0.1202,  0.3194, -0.9044,  1.0275,  0.0882, -2.1102,\n",
            "           1.0784]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0].mean(), out[0].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRjDQzZwsIAc",
        "outputId": "937dbbcb-5051-4b14-a272-1cb63bd4dc79"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.9868e-08, grad_fn=<MeanBackward0>),\n",
              " tensor(1.0215, grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Tokenization"
      ],
      "metadata": {
        "id": "slOi25swyVrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSYQ-Ftkzjfg",
        "outputId": "317a0062-7481-4fcd-fef1-36028f034c2c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = 'drive/MyDrive/train.en'\n",
        "kannada_file = 'drive/MyDrive/train.kn'"
      ],
      "metadata": {
        "id": "neDXcLK8zlvN"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'"
      ],
      "metadata": {
        "id": "doNlVlFCztSF"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '',\n",
        "                      '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', PADDING_TOKEN, END_TOKEN]"
      ],
      "metadata": {
        "id": "y0CPjApdzw74"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                        'Y', 'Z', '[', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z', '{', '|', '}', '~', '\\\\', PADDING_TOKEN, END_TOKEN]"
      ],
      "metadata": {
        "id": "sc5LOPRWz1u-"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "tuple(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccYqchgk4IYH",
        "outputId": "10ab1d09-dd98-4699-fb42-dbda8e685bca"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('', '', '', '', '')"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'' + ''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZyNdRGJt4Ojq",
        "outputId": "5750d96d-644c-431a-d118-09468e903a03"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
        "kanada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}"
      ],
      "metadata": {
        "id": "azoqjAmg4bkM"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ],
      "metadata": {
        "id": "TKTpGiUX4--S"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 100000"
      ],
      "metadata": {
        "id": "9s_jl1Yg4z83"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file, 'r') as f:\n",
        "  english_sentences = f.readlines()"
      ],
      "metadata": {
        "id": "xo-fk_DH470R"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(kannada_file, 'r') as f:\n",
        "  kannada_sentences = f.readlines()"
      ],
      "metadata": {
        "id": "Z4B-wv7S-MiR"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = english_sentences[: TOTAL_SENTENCES]\n",
        "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]"
      ],
      "metadata": {
        "id": "lbjILXlQ-hZf"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The rstrip() method removes any trailing characters (characters at the end a string),\n",
        "# space is the default trailing character to remove.\n",
        "english_sentences = [x.rstrip('\\n') for x in english_sentences]\n",
        "kannada_sentences = [x.rstrip('\\n') for x in kannada_sentences]"
      ],
      "metadata": {
        "id": "yfwQ_-CF_GdP"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTOs7aqCYHn",
        "outputId": "f66f9607-4058-4567-8203-066d1942c3c1"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hes a scientist.',\n",
              " \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
              " '8 lakh crore have been looted.',\n",
              " 'I read a lot into this as well.',\n",
              " \"She was found dead with the phone's battery exploded close to her head the following morning.\",\n",
              " 'How did mankind come under Satans rival sovereignty?',\n",
              " 'And then I became Prime Minister.',\n",
              " 'What about corruption?',\n",
              " 'No differences',\n",
              " '\"\"\"The shooting of the film is 90 percent done.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kannada_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sefHfLWQFIIs",
        "outputId": "34ce1e9e-08f2-4d89-eb2e-db84aaef088b"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  .',\n",
              " '\"        , \"\"     \"',\n",
              " ' 8  .',\n",
              " '    .',\n",
              " '    \\u200c     .',\n",
              " '     ?',\n",
              " '   .',\n",
              " ' ?',\n",
              " ' ',\n",
              " '   90    .']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(len(x) for x in kannada_sentences), max(len(x) for x in english_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcGAQe6iFL2o",
        "outputId": "50bbef3e-ad23-4044-a826-05c0319d70ab"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 722)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhRaCuGFSAz",
        "outputId": "0158cedd-f47a-4c3f-beae-dc071fae8176"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97th percentile length Kannada: 172.0\n",
            "97th percentile length English: 179.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 200"
      ],
      "metadata": {
        "id": "O7HxDGFoFmGX"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_tokens(sentence, vocab):\n",
        "  for token in list(set(sentence)):\n",
        "    if token not in vocab:\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "Y7Rwz_lXKEWx"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_length(sentence, max_sequence_length):\n",
        "  return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space"
      ],
      "metadata": {
        "id": "1okNFXckKhKh"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_sentence_indicies = []"
      ],
      "metadata": {
        "id": "B3XJ5S4rSTFL"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(kannada_sentences)):\n",
        "  kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
        "  if is_valid_length(kannada_sentence, max_sequence_length) and is_valid_length(english_sentence, max_sequence_length) and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
        "    valid_sentence_indicies.append(index)"
      ],
      "metadata": {
        "id": "0byhHNSGSVwV"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_sentence_indicies[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbRhasMUt0Y5",
        "outputId": "cc434b57-fd54-463b-8afc-7890d0a439c9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1TD4jQ8sQhg",
        "outputId": "dfd61d98-ded6-4a3b-baf7-5183751bbc8e"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 100000\n",
            "Number of valid sentences: 82070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ],
      "metadata": {
        "id": "gXTG8oKtsmnM"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(kannada_sentences[:3], english_sentences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XMzbhn3svfQ",
        "outputId": "a44885c9-0c0d-4726-d126-15cffa9d68a2"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['  .',\n",
              "  '\"        , \"\"     \"',\n",
              "  ' 8  .'],\n",
              " ['Hes a scientist.',\n",
              "  \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
              "  '8 lakh crore have been looted.'])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, english_sentences, kannada_sentences):\n",
        "    self.english_sentences = english_sentences\n",
        "    self.kannada_sentences = kannada_sentences\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.english_sentences)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.english_sentences[idx], self.kannada_sentences[idx]"
      ],
      "metadata": {
        "id": "xPFlMVpCs89l"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(english_sentences, kannada_sentences)"
      ],
      "metadata": {
        "id": "iPElJIUovqM6"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-tyraMev1Kw",
        "outputId": "81470ff2-6d38-40e7-d16f-fe67efccbb85"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82070"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9dxvGpjv50O",
        "outputId": "c684d030-f46c-4c55-f5f0-627bdf541357"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\",\n",
              " '\"        , \"\"     \"')"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ],
      "metadata": {
        "id": "_LHvn4_qv8e4"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "  print(batch)\n",
        "  if batch_num > 3:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04iPSZGEyX2w",
        "outputId": "484fd9d6-02c4-4e44-91e9-d3bb03102084"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hes a scientist.', \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\", '8 lakh crore have been looted.'), ('  .', '\"        , \"\"     \"', ' 8  .')]\n",
            "[('I read a lot into this as well.', 'How did mankind come under Satans rival sovereignty?', 'And then I became Prime Minister.'), ('    .', '     ?', '   .')]\n",
            "[('What about corruption?', '\"\"\"The shooting of the film is 90 percent done.\"', 'the Special Statute'), (' ?', '   90    .', ' ')]\n",
            "[('\"Then the king said to Ittai the Gittite, \"\"Why do you also go with us? Return, and stay with the king. for you are a foreigner, and also an exile. Return to your own place.\"', 'What happened at the UN General Assembly?', 'The meeting was attended by Prime Minister Narendra Modi, Home Minister Amit Shah and Defence Minister Rajnath Singh, among others.'), ('    --    ?       .    .', '     ?', '   ,                    .')]\n",
            "[('It has been under discussion for a long time.', 'Buses cannot get there.', 'Why then this tradition was not thought of?'), ('     .', '    .', '    ?')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
        "  sentence_word_indices = [language_to_index[token] for token in sentence]\n",
        "  if start_token:\n",
        "    sentence_word_indices.insert(0, language_to_index[START_TOKEN])\n",
        "  if end_token:\n",
        "    sentence_word_indices.append(language_to_index[END_TOKEN])\n",
        "  for _ in range(len(sentence_word_indices), max_sequence_length):\n",
        "    sentence_word_indices.append(language_to_index[PADDING_TOKEN])\n",
        "  return torch.tensor(sentence_word_indices)"
      ],
      "metadata": {
        "id": "8YzVo_eFybWP"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25xlkQXa37rr",
        "outputId": "e6537836-adbd-442c-83f1-0599cb310802"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It has been under discussion for a long time.',\n",
              "  'Buses cannot get there.',\n",
              "  'Why then this tradition was not thought of?'),\n",
              " ('     .',\n",
              "  '    .',\n",
              "  '    ?')]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0][0], batch[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBr72qcn39aJ",
        "outputId": "75c1f1e2-8121-40fe-c963-96714f62783a"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('It has been under discussion for a long time.',\n",
              " '     .')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized, kn_tokenized = [], []"
      ],
      "metadata": {
        "id": "n0Rp6r-h4KNB"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_num in range(batch_size):\n",
        "  eng_sentence, kn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "  eng_tokenized.append(tokenize(eng_sentence, english_to_index, start_token=False, end_token=False))\n",
        "  kn_tokenized.append(tokenize(kn_sentence, kanada_to_index, start_token=True, end_token=True))"
      ],
      "metadata": {
        "id": "isFWl0Ee4bHa"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWN-j9j6bcj",
        "outputId": "bc346686-2534-4e7f-cc5c-fbfed23c6984"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([41, 83,  1, 71, 64, 82,  1, 65, 68, 68, 77,  1, 84, 77, 67, 68, 81,  1,\n",
              "         67, 72, 82, 66, 84, 82, 82, 72, 78, 77,  1, 69, 78, 81,  1, 64,  1, 75,\n",
              "         78, 77, 70,  1, 83, 72, 76, 68, 15, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95]),\n",
              " tensor([34, 84, 82, 68, 82,  1, 66, 64, 77, 77, 78, 83,  1, 70, 68, 83,  1, 83,\n",
              "         71, 68, 81, 68, 15, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95]),\n",
              " tensor([55, 71, 88,  1, 83, 71, 68, 77,  1, 83, 71, 72, 82,  1, 83, 81, 64, 67,\n",
              "         72, 83, 72, 78, 77,  1, 86, 64, 82,  1, 77, 78, 83,  1, 83, 71, 78, 84,\n",
              "         70, 71, 83,  1, 78, 69, 31, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95])]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenates a sequence of tensors along a new dimension - default dim is 0\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "kn_tokenized = torch.stack(kn_tokenized)"
      ],
      "metadata": {
        "id": "EF9sU2sb6UTc"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_QLRnpP4flL",
        "outputId": "3ec82d7e-f766-4393-a34f-7f08d87b656c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[41, 83,  1, 71, 64, 82,  1, 65, 68, 68, 77,  1, 84, 77, 67, 68, 81,  1,\n",
              "         67, 72, 82, 66, 84, 82, 82, 72, 78, 77,  1, 69, 78, 81,  1, 64,  1, 75,\n",
              "         78, 77, 70,  1, 83, 72, 76, 68, 15, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [34, 84, 82, 68, 82,  1, 66, 64, 77, 77, 78, 83,  1, 70, 68, 83,  1, 83,\n",
              "         71, 68, 81, 68, 15, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95],\n",
              "        [55, 71, 88,  1, 83, 71, 68, 77,  1, 83, 71, 72, 82,  1, 83, 81, 64, 67,\n",
              "         72, 83, 72, 78, 77,  1, 86, 64, 82,  1, 77, 78, 83,  1, 83, 71, 78, 84,\n",
              "         70, 71, 83,  1, 78, 69, 31, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
              "         95, 95]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEG_INFTY = -1e9"
      ],
      "metadata": {
        "id": "gLORpCZ-5uRm"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padding masks to ignore padding tadding tokens for forward and backward prop/weight updation\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "  num_sentence = len(eng_batch)\n",
        "  look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
        "  look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "  encoder_padding_mask = torch.full([num_sentence, max_sequence_length, max_sequence_length], False)\n",
        "  decoder_padding_mask_self_attention = torch.full([num_sentence, max_sequence_length, max_sequence_length], False)\n",
        "  decoder_padding_mask_cross_attention = torch.full([num_sentence, max_sequence_length, max_sequence_length], False)\n",
        "\n",
        "  for idx in range(num_sentence):\n",
        "    eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "    eng_chars_to_padding_mask = np.arange(eng_sentence_length+1, max_sequence_length)\n",
        "    kn_chars_to_padding_mask = np.arange(kn_sentence_length+1, max_sequence_length)\n",
        "    encoder_padding_mask[idx, :,eng_chars_to_padding_mask] = True\n",
        "    encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "    decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "    decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "    decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "    decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "  encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "  decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "  decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "  print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
        "  print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
        "  print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
        "  return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ],
      "metadata": {
        "id": "z8k898t864Ip"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_masks(batch[0], batch[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdTnQzrgb4rC",
        "outputId": "7293a3d6-1de5-40b0-dd81-9a97905d4ba8"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "decoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
            "decoder_cross_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceEmbedding(nn.Module):\n",
        "  \"For a given sentence, create an embedding\"\n",
        "  def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "    super().__init__()\n",
        "    self.vocab_size = len(language_to_index)\n",
        "    self.max_sequence_length = max_sequence_length\n",
        "    self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "    self.language_to_index = language_to_index\n",
        "    self.position_encoder = PositionalEncoding(d_model = d_model, max_seq_len=max_sequence_length)\n",
        "    self.dropout = nn.Dropout(p=0.1)\n",
        "    self.START_TOKEN = START_TOKEN\n",
        "    self.END_TOKEN = END_TOKEN\n",
        "    self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "  def batch_tokenize(self, batch, start_token=True, end_token=True):\n",
        "\n",
        "    def tokenize(sentence, start_token=True, end_token=True):\n",
        "      sentence_word_indices = [self.language_to_index[token] for token in list(sentence)]\n",
        "      if start_token:\n",
        "        sentence_word_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "      if end_token:\n",
        "        sentence_word_indices.append(self.language_to_index[self.END_TOKEN])\n",
        "      for _ in range(len(sentence_word_indices), self.max_sequence_length):\n",
        "        sentence_word_indices.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "      return torch.tensor(sentence_word_indices)\n",
        "\n",
        "    tokenized = []\n",
        "\n",
        "    for sentence_num in range(len(batch)):\n",
        "      tokenized.append(tokenize(batch[sentence_num], start_token, end_token))\n",
        "\n",
        "    tokenized = torch.stack(tokenized)\n",
        "    return tokenized.to(torch.get_device())\n",
        "\n",
        "  def forward(self, x, end_token=True): #sentence\n",
        "    x = self.batch_tokenize(x, end_token)\n",
        "    x = self.embedding(x)\n",
        "    pos = self.position_encoder().to(torch.get_device())\n",
        "    x = self.dropout(x + pos)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NxjZWISgb8jc"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Encoder"
      ],
      "metadata": {
        "id": "0mLIyXPUkJCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "12SF6MwAkIhx"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    print(f\"scaled.size() : {scaled.size()}\")\n",
        "    if mask is not None:\n",
        "        print(f\"-- ADDING MASK of shape {mask.size()} --\")\n",
        "        # Broadcasting add. So just the last N dimensions need to match\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, max_sequence_length, d_model = x.size()\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "        values = values.reshape(batch_size, max_sequence_length, self.num_heads * self.head_dim)\n",
        "        print(f\"values.size(): {values.size()}\")\n",
        "        out = self.linear_layer(values)\n",
        "        print(f\"out.size(): {out.size()}\")\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean ({mean.size()})\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation  ({std.size()})\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y: {y.size()}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"self.gamma: {self.gamma.size()}, self.beta: {self.beta.size()}\")\n",
        "        print(f\"out: {out.size()}\")\n",
        "        return out\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "      super().__init__()\n",
        "      self.linear1 = nn.Linear(d_model, hidden)\n",
        "      self.linear2 = nn.Linear(hidden, d_model)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.linear1(x)\n",
        "      print(f\"x after first linear layer: {x.size()}\")\n",
        "      x = self.relu(x)\n",
        "      print(f\"x after activation: {x.size()}\")\n",
        "      x = self.dropout(x)\n",
        "      print(f\"x after dropout: {x.size()}\")\n",
        "      x = self.linear2(x)\n",
        "      print(f\"x after 2nd linear layer: {x.size()}\")\n",
        "      return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "    super().__init__()\n",
        "    self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "    self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1 = nn.Dropout(drop_prob)\n",
        "    self.ffn = PositionwiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
        "    self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2 = nn.Dropout(drop_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual_x = x\n",
        "    print(\"------- ATTENTION 1 ------\")\n",
        "    x = self.attention(x, mask=None)\n",
        "    print(\"------- DROPOUT 1 ------\")\n",
        "    x = self.dropout1(x)\n",
        "    print(\"------- ADD AND LAYER NORMALIZATION 1 ------\")\n",
        "    x = self.norm1(x + residual_x)\n",
        "    residual_x = x\n",
        "    print(\"------- ATTENTION 2 ------\")\n",
        "    x = self.ffn(x)\n",
        "    print(\"------- DROPOUT 2 ------\")\n",
        "    x = self.dropout2(x)\n",
        "    print(\"------- ADD AND LAYER NORMALIZATION 2 ------\")\n",
        "    x = self.norm2(x + residual_x)\n",
        "    return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NN6E4crsc4Pf"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5"
      ],
      "metadata": {
        "id": "j2NbbtbD1f9j"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
      ],
      "metadata": {
        "id": "n_yeT4Xk1xz9"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# includes positional encoding\n",
        "x = torch.randn((batch_size, max_sequence_length, d_model))"
      ],
      "metadata": {
        "id": "tZpV2K0E13aj"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRTYdyun19tT",
        "outputId": "a1ad2178-5f25-4279-9f38-10f11fa790e7"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Decoder"
      ],
      "metadata": {
        "id": "zeDMKTPhnKAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadCrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model) # 1024\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size() # 30 x 200 x 512\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        kv = self.kv_layer(x) # 30 x 200 x 1024\n",
        "        print(f\"kv.size(): {kv.size()}\")\n",
        "        q = self.q_layer(y) # 30 x 200 x 512\n",
        "        print(f\"q.size(): {q.size()}\")\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)  # 30 x 200 x 8 x 128\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)  # 30 x 200 x 8 x 64\n",
        "        kv = kv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 128\n",
        "        q = q.permute(0, 2, 1, 3) # 30 x 8 x 200 x 64\n",
        "        k, v = kv.chunk(2, dim=-1) # K: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) #  30 x 8 x 200 x 64\n",
        "        print(f\"values: {values.size()}, attention:{attention.size()}\")\n",
        "        values = values.reshape(batch_size, sequence_length, d_model) #  30 x 200 x 512\n",
        "        out = self.linear_layer(values)  #  30 x 200 x 512\n",
        "        print(f\"out after passing through linear layer: {out.size()}\")\n",
        "        return out  #  30 x 200 x 512"
      ],
      "metadata": {
        "id": "nVW5CUaK2D86"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "    super().__init__()\n",
        "    self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "    self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "    self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "    self.norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def forward(self, x, y, decoder_mask):\n",
        "    _y = y # 30 x 200 x 512\n",
        "    print(\"MASKED SELF ATTENTION\")\n",
        "    y = self.self_attention(y, decoder_mask)\n",
        "    print(\"DROP OUT 1\")\n",
        "    y = self.dropout1(y) # 30 x 200 x 512\n",
        "    print(\"ADD + LAYER NORMALIZATION 1\")\n",
        "    y = self.norm1(y + _y) # 30 x 200 x 512\n",
        "\n",
        "    _y=y\n",
        "    print(\"CROSS ATTENTION\")\n",
        "    y = self.encoder_decoder_attention(x, y, mask=None) # 30 x 200 x 512\n",
        "    print(\"DROP OUT 2\")  #30 x 200 x 512\n",
        "    y = self.dropout2(y)\n",
        "    print(\"ADD + LAYER NORMALIZATION 2\")\n",
        "    y = self.norm2(y + _y) #30 x 200 x 512\n",
        "\n",
        "    _y=y #30 x 200 x 512\n",
        "    print(\"FEED FORWARD 1\")\n",
        "    y = self.ffn(y) #30 x 200 x 512\n",
        "    print(\"DROP OUT 3\")\n",
        "    y=self.dropout3(y) #30 x 200 x 512\n",
        "    print(\"ADD + LAYER NORMALIZATION 3\")\n",
        "    y = self.norm3(y + _y) #30 x 200 x 512\n",
        "    return y #30 x 200 x 512"
      ],
      "metadata": {
        "id": "K3C6xD3qnP_v"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialDecoder(nn.Sequential):\n",
        "  def forward(self, *inputs):\n",
        "    x, y, mask = inputs\n",
        "    for module in self._modules.values():\n",
        "      y = module(x, y, mask) #30 x 200 x 512\n",
        "    return y"
      ],
      "metadata": {
        "id": "hljaFroIFpnQ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "\n",
        "  def forward(self, x, y, mask):\n",
        "    #x : 30 x 200 x 512\n",
        "    #y : 30 x 200 x 512\n",
        "    #mask : 200 x 200\n",
        "    y = self.layers(x, y, mask)\n",
        "    return y #30 x 200 x 512"
      ],
      "metadata": {
        "id": "_TCeBf6-GY9E"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5"
      ],
      "metadata": {
        "id": "1xQBE40LKOti"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn( (batch_size, max_sequence_length, d_model) ) # English sentence positional encoded\n",
        "y = torch.randn( (batch_size, max_sequence_length, d_model) ) # Kannada sentence positional encoded"
      ],
      "metadata": {
        "id": "U-qt72_1KYC-"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.full([max_sequence_length, max_sequence_length] , float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1)"
      ],
      "metadata": {
        "id": "-lhO9P9rKccT"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3tfwJ0IZOvd",
        "outputId": "95f20a61-f1d5-47b2-8875-86413367620d"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
              "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
              "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
              "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "out = decoder(x, y, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTFwemnpKeaB",
        "outputId": "ac24a32a-a83a-42a5-a6ba-c17061e0a0a5"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-fpWsAlKfmE"
      },
      "execution_count": 176,
      "outputs": []
    }
  ]
}