{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPMixer_pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6KhKC42XIV8VNBnxNYYNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganesh3/pytorch-work/blob/master/MLPMixer_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QoTbenzTTLb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import einops"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sid9zSy31RKo"
      },
      "source": [
        "class MlpBlock(nn.Module):\n",
        "  \"\"\"Multilayer Perceptron\n",
        "\n",
        "  Parameters\n",
        "  -----------\n",
        "  dim : int\n",
        "      Input and output dimension of the entire block. Inside of the mixer it will either be equal to 'n_patches' or 'hidden_dim'\n",
        "\n",
        "  mlp_dim : int\n",
        "          Dimension of the hidden layer\n",
        "\n",
        "  Attributes\n",
        "  -----------\n",
        "\n",
        "  linear_1, linear_2 : nn.Linear\n",
        "          Linear Layers.\n",
        "\n",
        "  \n",
        "  activation : nn.GELU\n",
        "            activation.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dim, mlp_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    mlp_dim = dim if mlp_dim is None else mlp_dim\n",
        "    self.linear_1 = nn.Linear(dim, mlp_dim)\n",
        "    self.activation = nn.GELU()\n",
        "    self.linear_2 = nn.Linear(mlp_dim, dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Run the forward pass\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    x : torch.Tensor\n",
        "      Input tensor of shape '(n_samples, n_channels, n_patches)' or '(n_samples, n_patches, n_channels)'\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "    torch.Tensor\n",
        "      Output tensor will have the same shape as the input tensor 'x'.\n",
        "    \"\"\"\n",
        "\n",
        "    x = self.linear_1(x) #(n_samples, *, mlp_dim)\n",
        "    x = self.activation(x) #(n_samples, *, mlp_dim)\n",
        "    x = self.linear_2(x) #(n_samples, *, dim)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqKw7BQ1ROZ"
      },
      "source": [
        "class MixerBlock(nn.Module):\n",
        "  \"\"\"Mixer block that contains 2 'MLPBlock's' and 2 'LayerNorm's'\n",
        "\n",
        "  Parameters\n",
        "  -----------\n",
        "  n_patches : int\n",
        "        Number of patches the image is split up into.\n",
        "\n",
        "  hidden_dim : int\n",
        "        Dimensionality of patch embeddings.\n",
        "\n",
        "  tokens_mlp_dim : int\n",
        "        Hidden dimension for the 'MLPBlock' when doing the token mixing.\n",
        "\n",
        "  channels_mlp_dim : int\n",
        "        Hidden dimension for the 'MLPBlock' when doing the channel mixing\n",
        "\n",
        "  Attributes\n",
        "  -----------\n",
        "  norm_1, norm_2 : LayerNorm\n",
        "        Layer Normalization\n",
        "\n",
        "  token_mlp_block : MlpBlock\n",
        "        Token mixing NLP.\n",
        "\n",
        "  channel_mlp_block : MlpBlock\n",
        "        Channel mixing NLP.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, *, n_patches, hidden_dim, tokens_mlp_dim, channels_mlp_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.norm_1 = nn.LayerNorm(hidden_dim)\n",
        "    self.norm_2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    self.token_mlp_block = MlpBlock(n_patches, tokens_mlp_dim)\n",
        "    self.channel_mlp_block = MlpBlock(hidden_dim, channels_mlp_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Run the forward pass\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    x : torch.Tensor\n",
        "      Input tensor of shape '(n_samples, n_patches, hidden_dim)'\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "    torch.Tensor\n",
        "      Output tensor will have the same shape as the input tensor 'x' i.e. '(n_samples, n_patches, hidden_dim)'.\n",
        "    \"\"\"\n",
        "    y = self.norm_1(x) # (n_samples, n_patches, hidden_dim)\n",
        "    y = y.permute(0, 2, 1) # swap the hidden_dim and n_patches (n_samples, hidden_dim, n_patches)\n",
        "    y = self.token_mlp_block(y) # (n_samples, hidden_dim, n_patches)\n",
        "\n",
        "    y = y.permute(0, 2, 1) # swap the n_patches and hidden_dim (n_samples, n_patches, hidden_dim)\n",
        "    x = x + y # add y as a residual to the input (n_samples, n_patches, hidden_dim)\n",
        "    y = self.norm_2(x) #(n_samples, n_patches, hidden_dim)\n",
        "    res = x + self.channel_mlp_block(y) #(n_samples, n_patches, hidden_dim)\n",
        "    return res"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM_8L-Zw1RRz"
      },
      "source": [
        "class MlpMixer(nn.Module):\n",
        "  \"\"\"Entire network.\n",
        "\n",
        "  Parameters\n",
        "  -----------\n",
        "  image_size : int\n",
        "    Height and width (assuming it is a square) of the image\n",
        "\n",
        "  patch_size : int\n",
        "    Height and width (assuming it is a square) of the patches. Note that we assume that 'image_size % patch_size == 0'\n",
        "\n",
        "  tokens_mlp_dim : int\n",
        "    Hidden dimension for the 'MlpBlock' when doing the token mixing.\n",
        "\n",
        "  channel_mlp_dim : \n",
        "    Hidden dimension for the 'MlpBlock' when doing the channel mixing.\n",
        "\n",
        "  n_classes : int\n",
        "    Number of classes for classification\n",
        "  \n",
        "  hidden_dim : int\n",
        "    Dimensionality of patch embeddings\n",
        "\n",
        "  n_blocks : int\n",
        "    Number of 'MixerBlock' in the architecture.\n",
        "\n",
        "  Attributes\n",
        "  -----------\n",
        "\n",
        "  patch_embedder : nn.Conv2d\n",
        "    Splits the image up into multiple patches and then embeds each of them (using shared weights).\n",
        "\n",
        "  blocks : nn.ModuleList\n",
        "    List of MixerBlock instances.\n",
        "\n",
        "  pre_head_norm : nn.LayerNorm\n",
        "    LayerNormalization applied just before the classification head.\n",
        "\n",
        "  head_classifier : nn.Linear\n",
        "    The classification head.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, *, image_size, patch_size, tokens_mlp_dim, channels_mlp_dim, n_classes, hidden_dim, n_blocks, ):\n",
        "    super().__init__()\n",
        "\n",
        "    n_patches = (image_size // patch_size) ** 2 # assumes divisibility\n",
        "    self.patch_embedder = nn.Conv2d(3, hidden_dim, kernel_size=patch_size, stride = patch_size, )\n",
        "    self.blocks = nn.ModuleList([MixerBlock(n_patches=n_patches, hidden_dim=hidden_dim, tokens_mlp_dim=tokens_mlp_dim, channels_mlp_dim=channels_mlp_dim) \n",
        "                                for _ in range(n_blocks)])\n",
        "    self.pre_head_norm = nn.LayerNorm(hidden_dim)\n",
        "    self.head_classifier = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Run the forward pass\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    x : torch.Tensor\n",
        "      Input batch of square images of shape '(n_samples, n_channels, image_size, image_size)'\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "    torch.Tensor\n",
        "      Class logits of the shape '(n_samples, n_classes)'.\n",
        "    \"\"\"\n",
        "    x = self.patch_embedder(x) # (n_samples, hidden_dim, n_patches ** (1/2), n_patches ** (1/2))\n",
        "    x = einops.rearrange(x, \"n c h w -> n (h w) c\") # (n_samples, n_patches, hidden_dim)\n",
        "\n",
        "    for mixer_block in self.blocks:\n",
        "      x = mixer_block(x) # (n_samples, n_patches, hidden_dim)\n",
        "    \n",
        "    x = self.pre_head_norm(x) # (n_samples, n_patches, hidden_dim)\n",
        "    x = x.mean(dim = 1) # (n_samples, hidden_dim) - averaging across the token dimension\n",
        "    y = self.head_classifier(x) # (n_samples, n_classes)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_udfOz2ZQvM"
      },
      "source": [
        "### Token Mixing as a Convolution using Conv1d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWFUVbVuT8BL"
      },
      "source": [
        "###Token Mixing as a Convolution using Conv1d\n",
        "class conv1dDepthWiseShared(nn.Module):\n",
        "  def __init__(self, hidden_dim, kernel_size, k):\n",
        "    super().__init__()\n",
        "    #same as input channels of our tensor\n",
        "    self.hidden_dim = hidden_dim\n",
        "    # K is any number representing the output features\n",
        "    self.weight_shared = nn.Parameter(torch.rand(k, 1, kernel_size,))\n",
        "    self.bias_shared = nn.Parameter(torch.rand(k))\n",
        "\n",
        "  def forward(self, x):\n",
        "    weight = self.weight_shared.repeat(self.hidden_dim, 1, 1)\n",
        "    bias = self.bias_shared.repeat(self.hidden_dim)\n",
        "    res = torch.nn.functional.conv1d(x, weight=weight, bias=bias, groups=self.hidden_dim)\n",
        "    return res"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv1DmBxWW12y"
      },
      "source": [
        "n_samples, hidden_dim, n_patches = 2, 16, 25\n",
        "k = 7\n",
        "x = torch.rand(n_samples, hidden_dim, n_patches)\n",
        "module_conv = conv1dDepthWiseShared(hidden_dim, n_patches, k)\n",
        "module_linear = nn.Linear(n_patches, k)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b7bLAEcXAIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9a882f-eff3-467e-cb0c-dc556feaf830"
      },
      "source": [
        "sum(p.numel() for p in module_conv.parameters() if p.requires_grad), sum(p.numel() for p in module_linear.parameters() if p.requires_grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(182, 182)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sga06PzSXB8B"
      },
      "source": [
        "module_conv.weight_shared.data[:, 0, :] = module_linear.weight.data\n",
        "module_conv.bias_shared.data[:] = module_linear.bias.data"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6OA1KC5XMjk"
      },
      "source": [
        "out_conv = module_conv(x).reshape(n_samples, hidden_dim, k)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPJciQfTXY1E"
      },
      "source": [
        "out_linear = module_linear(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGd3YcFXAwIR",
        "outputId": "71da8c94-b8ca-4ca4-bd27-f7b397054e4f"
      },
      "source": [
        "out_conv.shape, out_linear.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 16, 7]), torch.Size([2, 16, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK8uq3bJXhQB",
        "outputId": "8eb5b740-b00c-4050-ff67-ceca1f11b4ce"
      },
      "source": [
        "torch.allclose(out_conv, out_linear, atol=1e-6, rtol=0) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zUqWM0hXyRH",
        "outputId": "805e8aa4-467b-4860-f12a-23401400b891"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmE01ANOX-lo"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9y9PELqYa_0"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhLUyFpYiEl"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTxNxuoAiktP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}